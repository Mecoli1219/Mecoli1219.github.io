(self.webpackChunk_N_E=self.webpackChunk_N_E||[]).push([[548],{7202:function(e,a,t){(window.__NEXT_P=window.__NEXT_P||[]).push(["/publications",function(){return t(7591)}])},7591:function(e,a,t){"use strict";t.r(a),t.d(a,{default:function(){return l}});var n=t(1527);t(959);var i={interest:["I have a keen interest in exploring various aspects of machine learning, such as natural language processing and reinforcement learning. Representative papers are highlighted."],researchList:[{image:{src:"/_next/static/media/av-superb.071d084a.png",height:1269,width:4501,blurDataURL:"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAgAAAACCAYAAABllJ3tAAAAQ0lEQVR4nGN8kasSwfCNVbFj8+sNE169ERZnZuB6+ZcBBNiB+ANIQTRQgUz7xtfrJ755oyDFwvjp2Z//bEBJLiD+BgBEZhh+ptX3oAAAAABJRU5ErkJggg==",blurWidth:8,blurHeight:2},title:"AV-SUPERB: A Multi-Task Evaluation Benchmark for Audio-Visual Representation Models",link:"https://av.superbbenchmark.org/",authors:[{name:"Yuan Tseng"},{name:"Layne Berry*"},{name:"Yi-Ting Chen*"},{name:"I-Hsiang Chiu*"},{name:"Hsuan-Hao Lin*"},{name:"Max Liu*"},{name:"Puyuan Peng*"},{name:"Yi-Jen Shih*"},{name:"Hung-Yu Wang*"},{name:"Haibin Wu*"},{name:"Po-Yao Huang"},{name:"Chun-Mao Lai",link:"https://www.mecoli.net/",me:!0},{name:"Shang-Wen Li"},{name:"David Harwath"},{name:"Yu Tsao"},{name:"Shinji Watanabe"},{name:"Abdelrahman Mohamed"},{name:"Chi-Luen Feng"},{name:"Hung-yi Lee",link:"https://speech.ee.ntu.edu.tw/~hylee/index.php"}],journal:"IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)",year:"2024",description:"We propose the AV-SUPERB benchmark that enables general-purpose evaluation of unimodal audio/visual and bimodal fusion representations on 7 datasets covering 5 audio-visual tasks in speech and audio processing.",others:{"Project Page":"https://av.superbbenchmark.org/",arXiv:"https://arxiv.org/abs/2309.10787",Code:"https://github.com/roger-tseng/av-superb"}},{image:{src:"/_next/static/media/dbc.50e3c8b5.png",height:768,width:1024,blurDataURL:"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAgAAAAGCAMAAADJ2y/JAAAAVFBMVEX////+/v79/v79/f39/Pz8/Pz9+/r7+/v6+vr5+vr5+fn5+Pf4+Pj49/f39/f59fX09fbz9ff19PT09PXz8/Py8vLw8PD07uzv7+/z7ezh5uvZ2ttDf4t2AAAAOElEQVR42iXByQGAIAwEwI0ag+styNl/nzyYgfH13xoOzK4+Z9oU6jAw0xv3BRZiu6ZyQ3+BUNABN6MB7PGgwckAAAAASUVORK5CYII=",blurWidth:8,blurHeight:6},title:"Diffusion Model-Augmented Behavioral Cloning",link:"https://nturobotlearninglab.github.io/dbc/",authors:[{name:"Hsiang-Chun Wang*"},{name:"Shang-Fu Chen*"},{name:"Ming-Hao Hsu",link:"https://qaz159qaz159.github.io/"},{name:"Chun-Mao Lai",link:"https://www.mecoli.net/",me:!0},{name:"Shao-Hua Sun",link:"https://shaohua0116.github.io/"}],journal:"Frontiers4LCD Workshop at International Conference on Machine Learning (ICML)",year:"2023",description:"We propose a novel imitation learning method combining with diffusion model. We show that our method can achieve better performance than previous imitation learning methods.",others:{"Project Page":"https://nturobotlearninglab.github.io/dbc/",arXiv:"https://arxiv.org/abs/2302.13335"}},{image:{src:"/_next/static/media/cuda-dst.740e7988.png",height:444,width:1216,blurDataURL:"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAgAAAADCAIAAAAhqtkfAAAAR0lEQVR42gVAUQ6AIAj1/mcsbYZKafDSZPOvOQXMbIvXnjXwoIqzega5D7Jmp8T7kX0kKumR8I7iwLFxlrv0xlMThLvWZfoDpZ5B/fpScs0AAAAASUVORK5CYII=",blurWidth:8,blurHeight:3},title:"Controllable User Dialogue Act Augmentation for Dialogue State Tracking",link:"https://arxiv.org/abs/2207.12757",authors:[{name:"Chun-Mao Lai*",link:"https://www.mecoli.net/",me:!0},{name:"Ming-Hao Hsu*",link:"https://qaz159qaz159.github.io/"},{name:"Chao-Wei Huang",link:"https://scholar.google.com/citations?user=nmsPLncAAAAJ"},{name:"Yun-Nung Chen",link:"https://www.csie.ntu.edu.tw/~yvchen/"}],journal:"23rd Annual Meeting of the Special Interest Group on Discourse and Dialogue (SIGDIAL)",year:"2022",description:"We propose a data augmentation method for DST, which improve the state-of-the-art performance on MultiWOZ 2.1.",others:{arXiv:"https://arxiv.org/abs/2207.12757",Code:"https://github.com/miulab/cuda-dst"}}]},r=t(8188),s=t.n(r);function o(e){let{research:a,index:t}=e;return(0,n.jsxs)(n.Fragment,{children:[(0,n.jsxs)("div",{className:"flex flex-col md:flex-row py-5 px-0 lg:px-5 justify-center items-center content-center",children:[(0,n.jsx)("div",{className:"lg:mr-5 max-md:max-w-96 max-md:mx-5 md:basis-2/6 lg:basis-1/4 md:min-h-48 mx-auto rounded-2xl overflow-hidden border flex justify-center items-center content-center bg-white h-fit max-md:mb-5",children:(0,n.jsx)(s(),{src:a.image,alt:a.title,className:"object-cover",priority:!0})}),(0,n.jsxs)("div",{className:"basis-full md:basis-4/6 lg:basis-3/4 pl-5 max-md:pr-5",children:[(0,n.jsx)("div",{className:"pb-2",children:(0,n.jsx)("a",{className:"text-lg font-bold ",href:a.link,children:a.title})}),a.authors.map((e,t)=>(0,n.jsxs)("div",{className:"inline",children:[void 0!==e.link?(0,n.jsx)("a",{href:e.link,className:"text-base hover:underline text-blue-500 dark:text-blue-300"+(e.me?" font-bold":" font-light"),children:e.name}):(0,n.jsx)("span",{className:"text-base text-gray-500 dark:text-gray-300 font-light",children:e.name}),t!==a.authors.length-1?(0,n.jsx)("span",{className:"text-base text-gray-500 dark:text-gray-300",children:", "}):(0,n.jsx)(n.Fragment,{})]},t)),(0,n.jsxs)("div",{className:"text-base text-black dark:text-white font-normal",children:[a.journal,", ",a.year]}),(0,n.jsx)("div",{className:"text-base text-gray-500 dark:text-gray-300 py-2 font-light max-sm:hidden ",children:a.description},""),Object.entries(a.others).map((e,a)=>{let[t,i]=e;return(0,n.jsxs)("div",{className:"inline pr-1",children:["[ ",(0,n.jsx)("a",{href:i,className:"hover:underline text-blue-500 dark:text-blue-300",children:t})," ]"]},a)})]})]}),t!==i.researchList.length-1?(0,n.jsx)("div",{className:"mx-3 md:mx-0 lg:mx-3 border-gray-400 border box-border mt-5 mb-12 md:my-2"},t):(0,n.jsx)(n.Fragment,{})]})}var l=function(){return(0,n.jsx)(n.Fragment,{children:(0,n.jsxs)("div",{className:"max-w-screen mx-auto flex flex-col px-5 md:px-20",children:[(0,n.jsx)("h1",{className:"text-4xl sm:text-5xl md:text-5xl font-bold pt-10 pb-5 text-center",children:"Publications."}),(0,n.jsx)("div",{className:"text-container max-w-md mx-auto pt-2 border-t-2 border-gray-400",children:(0,n.jsx)("p",{className:"leading-normal text-xl pb-5 text-center text-gray-500 dark:text-gray-300",children:"Depth fuels expertise, breadth sparks innovation."})}),(0,n.jsx)("div",{className:"h-12"}),i.researchList.map((e,a)=>(0,n.jsx)(o,{research:e,index:a},a))]})})}}},function(e){e.O(0,[188,774,888,179],function(){return e(e.s=7202)}),_N_E=e.O()}]);