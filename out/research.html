<!DOCTYPE html><html><head><meta charSet="utf-8"/><title>Chun-Mao Lai</title><meta name="viewport" content="width=device-width, initial-scale=1"/><meta name="theme-color" content="#F1F1F1"/><meta name="description" content="Chun-Mao (Michael) Lai&#x27;s personal website"/><meta property="og:image" content="/favicon.ico"/><meta property="og:image:type" content="image/png"/><meta property="og:url" content="www.mecoli.net"/><meta property="og:title" content="Chun-Mao Lai"/><meta property="og:description" content="Chun-Mao (Michael) Lai&#x27;s personal website"/><meta http-equiv="Permissions-Policy" content="interest-cohort=()"/><meta name="next-head-count" content="11"/><link rel="preload" href="/_next/static/css/167f8f58c6c5c084.css" as="style"/><link rel="stylesheet" href="/_next/static/css/167f8f58c6c5c084.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-8fa1640cc84ba8fe.js" defer=""></script><script src="/_next/static/chunks/framework-8d78bf989db74c8f.js" defer=""></script><script src="/_next/static/chunks/main-acebcc1890c682d6.js" defer=""></script><script src="/_next/static/chunks/pages/_app-d95077f924e38d65.js" defer=""></script><script src="/_next/static/chunks/pages/research-c03437588b1b26e9.js" defer=""></script><script src="/_next/static/jhiMK7zUou2lRdk9JAG7E/_buildManifest.js" defer=""></script><script src="/_next/static/jhiMK7zUou2lRdk9JAG7E/_ssgManifest.js" defer=""></script></head><body><div id="__next"><script>!function(){try{var d=document.documentElement,c=d.classList;c.remove('light','dark');var e=localStorage.getItem('theme');if('system'===e||(!e&&false)){var t='(prefers-color-scheme: dark)',m=window.matchMedia(t);if(m.media!==t||m.matches){d.style.colorScheme = 'dark';c.add('dark')}else{d.style.colorScheme = 'light';c.add('light')}}else if(e){c.add(e|| '')}else{c.add('light')}if(e==='light'||e==='dark'||!e)d.style.colorScheme=e||'light'}catch(e){}}()</script><div class="bg-[#F1F1F1] mt-0 dark:bg-gray-900 font-sans -z-50"><div class="relative top-0 "><div class="transition-top duration-500 max-w-full mx-auto px-4 py-10 h-32 fixed left-0 right-0 z-nav 
          top-0  
          bg-[#F1F1F1] mt-0 dark:bg-gray-900"><div class="flex md:flex-row justify-between items-center max-w-6xl mx-auto"><div class="flex flex-col "><a href="/"><div class="font-semibold text-xl text-gray-700 dark:text-white inline">Chun-Mao Lai</div><div class="text-xl font-light text-gray-500 dark:text-gray-300 inline pl-1"> Website</div></a></div><div class="lg:space-x-5 hidden lg:block"><a class="text-base hover:bg-white hover:dark:bg-gray-800 hover:shadow-lg px-2 py-3 rounded-lg border border-transparent text-gray-600 dark:text-gray-300 font-light" href="/about">About</a><a class="text-base hover:bg-white hover:dark:bg-gray-800 hover:shadow-lg px-2 py-3 rounded-lg border border-transparent text-gray-800 font-bold dark:text-gray-400" href="/research">Research</a><a class="text-base hover:bg-white hover:dark:bg-gray-800 hover:shadow-lg px-2 py-3 rounded-lg border border-transparent text-gray-600 dark:text-gray-300 font-light" href="/resume/main.pdf">Resume</a></div><div class="space-x-4 items-center hidden lg:flex flex-row "><a href="https://github.com/mecoli1219"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-github h-5 w-5" viewBox="0 0 16 16"><path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.012 8.012 0 0 0 16 8c0-4.42-3.58-8-8-8z"></path></svg></a><a href="https://www.facebook.com/michael.lai.1291/"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-facebook h-5 w-5" viewBox="0 0 16 16"><path d="M16 8.049c0-4.446-3.582-8.05-8-8.05C3.58 0-.002 3.603-.002 8.05c0 4.017 2.926 7.347 6.75 7.951v-5.625h-2.03V8.05H6.75V6.275c0-2.017 1.195-3.131 3.022-3.131.876 0 1.791.157 1.791.157v1.98h-1.009c-.993 0-1.303.621-1.303 1.258v1.51h2.218l-.354 2.326H9.25V16c3.824-.604 6.75-3.934 6.75-7.951z"></path></svg></a><a href="https://www.instagram.com/michaellai901026/"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-instagram h-5 w-5" viewBox="0 0 16 16"><path d="M8 0C5.829 0 5.556.01 4.703.048 3.85.088 3.269.222 2.76.42a3.917 3.917 0 0 0-1.417.923A3.927 3.927 0 0 0 .42 2.76C.222 3.268.087 3.85.048 4.7.01 5.555 0 5.827 0 8.001c0 2.172.01 2.444.048 3.297.04.852.174 1.433.372 1.942.205.526.478.972.923 1.417.444.445.89.719 1.416.923.51.198 1.09.333 1.942.372C5.555 15.99 5.827 16 8 16s2.444-.01 3.298-.048c.851-.04 1.434-.174 1.943-.372a3.916 3.916 0 0 0 1.416-.923c.445-.445.718-.891.923-1.417.197-.509.332-1.09.372-1.942C15.99 10.445 16 10.173 16 8s-.01-2.445-.048-3.299c-.04-.851-.175-1.433-.372-1.941a3.926 3.926 0 0 0-.923-1.417A3.911 3.911 0 0 0 13.24.42c-.51-.198-1.092-.333-1.943-.372C10.443.01 10.172 0 7.998 0h.003zm-.717 1.442h.718c2.136 0 2.389.007 3.232.046.78.035 1.204.166 1.486.275.373.145.64.319.92.599.28.28.453.546.598.92.11.281.24.705.275 1.485.039.843.047 1.096.047 3.231s-.008 2.389-.047 3.232c-.035.78-.166 1.203-.275 1.485a2.47 2.47 0 0 1-.599.919c-.28.28-.546.453-.92.598-.28.11-.704.24-1.485.276-.843.038-1.096.047-3.232.047s-2.39-.009-3.233-.047c-.78-.036-1.203-.166-1.485-.276a2.478 2.478 0 0 1-.92-.598 2.48 2.48 0 0 1-.6-.92c-.109-.281-.24-.705-.275-1.485-.038-.843-.046-1.096-.046-3.233 0-2.136.008-2.388.046-3.231.036-.78.166-1.204.276-1.486.145-.373.319-.64.599-.92.28-.28.546-.453.92-.598.282-.11.705-.24 1.485-.276.738-.034 1.024-.044 2.515-.045v.002zm4.988 1.328a.96.96 0 1 0 0 1.92.96.96 0 0 0 0-1.92zm-4.27 1.122a4.109 4.109 0 1 0 0 8.217 4.109 4.109 0 0 0 0-8.217zm0 1.441a2.667 2.667 0 1 1 0 5.334 2.667 2.667 0 0 1 0-5.334z"></path></svg></a><button aria-label="Toggle Dark Mode" type="button" class="w-10 h-10 p-3 rounded focus:outline-none"></button></div><div class="flex flex-row-reverse justify-between items-center lg:hidden"><button aria-label="Menu" title="Menu" class="dark:text-white block px-4 py-3 hover:bg-white hover:shadow-lg right-0"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="currentColor" class="bi bi-list text-gray-800 dark:text-white" viewBox="0 0 16 16"><path fill-rule="evenodd" class="text-gray-800 dark:text-white" d="M0 3.5A.5.5 0 0 1 .5 3h15a.5.5 0 0 1 0 1h-15A.5.5 0 0 1 0 3.5zm0 5A.5.5 0 0 1 .5 8h15a.5.5 0 0 1 0 1h-15A.5.5 0 0 1 0 8.5zm0 5A.5.5 0 0 1 .5 13h15a.5.5 0 0 1 0 1h-15A.5.5 0 0 1 0 13.5z"></path></svg></button></div></div></div></div><div class="max-w-full mx-auto relative  top-0 left-0 right-0 h-32 bg-transparent"></div><div class="max-w-7xl mx-auto flex flex-row overflow-hidden min-h-60screen"><div class="basis-5/5 md:basis-5/5"><div class="px-5 md:px-20 pt-5"><h1 class="text-5xl md:text-5xl font-bold py-10 text-center md:text-left">Research.</h1><div class="text-base text-gray-500 dark:text-gray-300 pb-5 indent-8">I have a keen interest in exploring various aspects of machine learning, such as natural language processing and reinforcement learning. Representative papers are highlighted.</div><div class="h-12"></div><div><div class="flex flex-col md:flex-row py-5 px-0 lg:px-5 justify-center items-center content-center"><div class="lg:mr-5 max-md:max-w-96 max-md:mx-5 md:basis-2/6 lg:basis-1/4 md:min-h-48 mx-auto rounded-2xl overflow-hidden border flex justify-center items-center content-center bg-white h-fit max-md:mb-5"><img src="static/research/av-superb.png" class="object-cover" alt=""/></div><div class="basis-full md:basis-4/6 lg:basis-3/4 pl-5 max-md:pr-5"><div class="pb-2"><a class="text-lg font-bold " href="https://av.superbbenchmark.org/">AV-SUPERB: A Multi-Task Evaluation Benchmark for Audio-Visual Representation Models</a></div><div class="inline"><span class="text-base text-gray-500 dark:text-gray-300 font-light">Yuan Tseng</span><span class="text-base text-gray-500 dark:text-gray-300">, </span></div><div class="inline"><span class="text-base text-gray-500 dark:text-gray-300 font-light">Layne Berry*</span><span class="text-base text-gray-500 dark:text-gray-300">, </span></div><div class="inline"><span class="text-base text-gray-500 dark:text-gray-300 font-light">Yi-Ting Chen*</span><span class="text-base text-gray-500 dark:text-gray-300">, </span></div><div class="inline"><span class="text-base text-gray-500 dark:text-gray-300 font-light">I-Hsiang Chiu*</span><span class="text-base text-gray-500 dark:text-gray-300">, </span></div><div class="inline"><span class="text-base text-gray-500 dark:text-gray-300 font-light">Hsuan-Hao Lin*</span><span class="text-base text-gray-500 dark:text-gray-300">, </span></div><div class="inline"><span class="text-base text-gray-500 dark:text-gray-300 font-light">Max Liu*</span><span class="text-base text-gray-500 dark:text-gray-300">, </span></div><div class="inline"><span class="text-base text-gray-500 dark:text-gray-300 font-light">Puyuan Peng*</span><span class="text-base text-gray-500 dark:text-gray-300">, </span></div><div class="inline"><span class="text-base text-gray-500 dark:text-gray-300 font-light">Yi-Jen Shih*</span><span class="text-base text-gray-500 dark:text-gray-300">, </span></div><div class="inline"><span class="text-base text-gray-500 dark:text-gray-300 font-light">Hung-Yu Wang*</span><span class="text-base text-gray-500 dark:text-gray-300">, </span></div><div class="inline"><span class="text-base text-gray-500 dark:text-gray-300 font-light">Haibin Wu*</span><span class="text-base text-gray-500 dark:text-gray-300">, </span></div><div class="inline"><span class="text-base text-gray-500 dark:text-gray-300 font-light">Po-Yao Huang</span><span class="text-base text-gray-500 dark:text-gray-300">, </span></div><div class="inline"><a href="https://www.mecoli.net/" class="text-base hover:underline text-blue-500 dark:text-blue-300 font-bold">Chun-Mao Lai</a><span class="text-base text-gray-500 dark:text-gray-300">, </span></div><div class="inline"><span class="text-base text-gray-500 dark:text-gray-300 font-light">Shang-Wen Li</span><span class="text-base text-gray-500 dark:text-gray-300">, </span></div><div class="inline"><span class="text-base text-gray-500 dark:text-gray-300 font-light">David Harwath</span><span class="text-base text-gray-500 dark:text-gray-300">, </span></div><div class="inline"><span class="text-base text-gray-500 dark:text-gray-300 font-light">Yu Tsao</span><span class="text-base text-gray-500 dark:text-gray-300">, </span></div><div class="inline"><span class="text-base text-gray-500 dark:text-gray-300 font-light">Shinji Watanabe</span><span class="text-base text-gray-500 dark:text-gray-300">, </span></div><div class="inline"><span class="text-base text-gray-500 dark:text-gray-300 font-light">Abdelrahman Mohamed</span><span class="text-base text-gray-500 dark:text-gray-300">, </span></div><div class="inline"><span class="text-base text-gray-500 dark:text-gray-300 font-light">Chi-Luen Feng</span><span class="text-base text-gray-500 dark:text-gray-300">, </span></div><div class="inline"><a href="https://speech.ee.ntu.edu.tw/~hylee/index.php" class="text-base hover:underline text-blue-500 dark:text-blue-300 font-light">Hung-yi Lee</a></div><div class="text-base text-black dark:text-gray-300 font-normal">IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)<!-- -->, <!-- -->2024</div><div class="text-base text-gray-500 dark:text-gray-300 py-2 font-light max-sm:hidden ">We propose the AV-SUPERB benchmark that enables general-purpose evaluation of unimodal audio/visual and bimodal fusion representations on 7 datasets covering 5 audio-visual tasks in speech and audio processing.</div><div class="inline pr-1">[ <a href="https://av.superbbenchmark.org/" class="hover:underline text-blue-500 dark:text-blue-300">Project Page</a> ]</div><div class="inline pr-1">[ <a href="https://arxiv.org/abs/2309.10787" class="hover:underline text-blue-500 dark:text-blue-300">arXiv</a> ]</div><div class="inline pr-1">[ <a href="https://github.com/roger-tseng/av-superb" class="hover:underline text-blue-500 dark:text-blue-300">Code</a> ]</div></div></div><div class="mx-3 md:mx-0 lg:mx-3 border-gray-400 border box-border mt-5 mb-12 md:my-2"></div></div><div><div class="flex flex-col md:flex-row py-5 px-0 lg:px-5 justify-center items-center content-center"><div class="lg:mr-5 max-md:max-w-96 max-md:mx-5 md:basis-2/6 lg:basis-1/4 md:min-h-48 mx-auto rounded-2xl overflow-hidden border flex justify-center items-center content-center bg-white h-fit max-md:mb-5"><img src="static/research/dbc.png" class="object-cover" alt=""/></div><div class="basis-full md:basis-4/6 lg:basis-3/4 pl-5 max-md:pr-5"><div class="pb-2"><a class="text-lg font-bold " href="https://nturobotlearninglab.github.io/dbc/">Diffusion Model-Augmented Behavioral Cloning</a></div><div class="inline"><span class="text-base text-gray-500 dark:text-gray-300 font-light">Hsiang-Chun Wang*</span><span class="text-base text-gray-500 dark:text-gray-300">, </span></div><div class="inline"><span class="text-base text-gray-500 dark:text-gray-300 font-light">Shang-Fu Chen*</span><span class="text-base text-gray-500 dark:text-gray-300">, </span></div><div class="inline"><a href="https://qaz159qaz159.github.io/" class="text-base hover:underline text-blue-500 dark:text-blue-300 font-light">Ming-Hao Hsu</a><span class="text-base text-gray-500 dark:text-gray-300">, </span></div><div class="inline"><a href="https://www.mecoli.net/" class="text-base hover:underline text-blue-500 dark:text-blue-300 font-bold">Chun-Mao Lai</a><span class="text-base text-gray-500 dark:text-gray-300">, </span></div><div class="inline"><a href="https://shaohua0116.github.io/" class="text-base hover:underline text-blue-500 dark:text-blue-300 font-light">Shao-Hua Sun</a></div><div class="text-base text-black dark:text-gray-300 font-normal">Frontiers4LCD Workshop at International Conference on Machine Learning (ICML)<!-- -->, <!-- -->2023</div><div class="text-base text-gray-500 dark:text-gray-300 py-2 font-light max-sm:hidden ">We propose a novel imitation learning method combining with diffusion model. We show that our method can achieve better performance than previous imitation learning methods.</div><div class="inline pr-1">[ <a href="https://nturobotlearninglab.github.io/dbc/" class="hover:underline text-blue-500 dark:text-blue-300">Project Page</a> ]</div><div class="inline pr-1">[ <a href="https://arxiv.org/abs/2302.13335" class="hover:underline text-blue-500 dark:text-blue-300">arXiv</a> ]</div></div></div><div class="mx-3 md:mx-0 lg:mx-3 border-gray-400 border box-border mt-5 mb-12 md:my-2"></div></div><div><div class="flex flex-col md:flex-row py-5 px-0 lg:px-5 justify-center items-center content-center"><div class="lg:mr-5 max-md:max-w-96 max-md:mx-5 md:basis-2/6 lg:basis-1/4 md:min-h-48 mx-auto rounded-2xl overflow-hidden border flex justify-center items-center content-center bg-white h-fit max-md:mb-5"><img src="static/research/cuda-dst.png" class="object-cover" alt=""/></div><div class="basis-full md:basis-4/6 lg:basis-3/4 pl-5 max-md:pr-5"><div class="pb-2"><a class="text-lg font-bold " href="https:/Xi.org/abs/2106.01598">Controllable User Dialogue Act Augmentation for Dialogue State Tracking</a></div><div class="inline"><a href="https://www.mecoli.net/" class="text-base hover:underline text-blue-500 dark:text-blue-300 font-bold">Chun-Mao Lai*</a><span class="text-base text-gray-500 dark:text-gray-300">, </span></div><div class="inline"><a href="https://qaz159qaz159.github.io/" class="text-base hover:underline text-blue-500 dark:text-blue-300 font-light">Ming-Hao Hsu*</a><span class="text-base text-gray-500 dark:text-gray-300">, </span></div><div class="inline"><a href="https://scholar.google.com/citations?user=nmsPLncAAAAJ" class="text-base hover:underline text-blue-500 dark:text-blue-300 font-light">Chao-Wei Huang</a><span class="text-base text-gray-500 dark:text-gray-300">, </span></div><div class="inline"><a href="https://www.csie.ntu.edu.tw/~yvchen/" class="text-base hover:underline text-blue-500 dark:text-blue-300 font-light">Yun-Nung Chen</a></div><div class="text-base text-black dark:text-gray-300 font-normal">23rd Annual Meeting of the Special Interest Group on Discourse and Dialogue (SIGDIAL)<!-- -->, <!-- -->2022</div><div class="text-base text-gray-500 dark:text-gray-300 py-2 font-light max-sm:hidden ">We propose a data augmentation method for DST, which improve the state-of-the-art performance on MultiWOZ 2.1.</div><div class="inline pr-1">[ <a href="https://arxiv.org/abs/2207.12757" class="hover:underline text-blue-500 dark:text-blue-300">arXiv</a> ]</div><div class="inline pr-1">[ <a href="https://github.com/miulab/cuda-dst" class="hover:underline text-blue-500 dark:text-blue-300">Code</a> ]</div></div></div></div></div></div></div><div class="h-48"></div></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{}},"page":"/research","query":{},"buildId":"jhiMK7zUou2lRdk9JAG7E","nextExport":true,"autoExport":true,"isFallback":false,"scriptLoader":[]}</script></body></html>