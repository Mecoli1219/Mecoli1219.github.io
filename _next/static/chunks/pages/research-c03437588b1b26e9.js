(self.webpackChunk_N_E=self.webpackChunk_N_E||[]).push([[465],{9004:function(e,a,n){(window.__NEXT_P=window.__NEXT_P||[]).push(["/research",function(){return n(7088)}])},7088:function(e,a,n){"use strict";n.r(a),n.d(a,{default:function(){return s}});var t=n(1527),i={interest:["I have a keen interest in exploring various aspects of machine learning, such as natural language processing and reinforcement learning. Representative papers are highlighted."],researchList:[{image:"static/research/av-superb.png",title:"AV-SUPERB: A Multi-Task Evaluation Benchmark for Audio-Visual Representation Models",link:"https://av.superbbenchmark.org/",authors:[{name:"Yuan Tseng"},{name:"Layne Berry*"},{name:"Yi-Ting Chen*"},{name:"I-Hsiang Chiu*"},{name:"Hsuan-Hao Lin*"},{name:"Max Liu*"},{name:"Puyuan Peng*"},{name:"Yi-Jen Shih*"},{name:"Hung-Yu Wang*"},{name:"Haibin Wu*"},{name:"Po-Yao Huang"},{name:"Chun-Mao Lai",link:"https://www.mecoli.net/",me:!0},{name:"Shang-Wen Li"},{name:"David Harwath"},{name:"Yu Tsao"},{name:"Shinji Watanabe"},{name:"Abdelrahman Mohamed"},{name:"Chi-Luen Feng"},{name:"Hung-yi Lee",link:"https://speech.ee.ntu.edu.tw/~hylee/index.php"}],journal:"IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)",year:"2024",description:"We propose the AV-SUPERB benchmark that enables general-purpose evaluation of unimodal audio/visual and bimodal fusion representations on 7 datasets covering 5 audio-visual tasks in speech and audio processing.",others:{"Project Page":"https://av.superbbenchmark.org/",arXiv:"https://arxiv.org/abs/2309.10787",Code:"https://github.com/roger-tseng/av-superb"}},{image:"static/research/dbc.png",title:"Diffusion Model-Augmented Behavioral Cloning",link:"https://nturobotlearninglab.github.io/dbc/",authors:[{name:"Hsiang-Chun Wang*"},{name:"Shang-Fu Chen*"},{name:"Ming-Hao Hsu",link:"https://qaz159qaz159.github.io/"},{name:"Chun-Mao Lai",link:"https://www.mecoli.net/",me:!0},{name:"Shao-Hua Sun",link:"https://shaohua0116.github.io/"}],journal:"Frontiers4LCD Workshop at International Conference on Machine Learning (ICML)",year:"2023",description:"We propose a novel imitation learning method combining with diffusion model. We show that our method can achieve better performance than previous imitation learning methods.",others:{"Project Page":"https://nturobotlearninglab.github.io/dbc/",arXiv:"https://arxiv.org/abs/2302.13335"}},{image:"static/research/cuda-dst.png",title:"Controllable User Dialogue Act Augmentation for Dialogue State Tracking",link:"https:/Xi.org/abs/2106.01598",authors:[{name:"Chun-Mao Lai*",link:"https://www.mecoli.net/",me:!0},{name:"Ming-Hao Hsu*",link:"https://qaz159qaz159.github.io/"},{name:"Chao-Wei Huang",link:"https://scholar.google.com/citations?user=nmsPLncAAAAJ"},{name:"Yun-Nung Chen",link:"https://www.csie.ntu.edu.tw/~yvchen/"}],journal:"23rd Annual Meeting of the Special Interest Group on Discourse and Dialogue (SIGDIAL)",year:"2022",description:"We propose a data augmentation method for DST, which improve the state-of-the-art performance on MultiWOZ 2.1.",others:{arXiv:"https://arxiv.org/abs/2207.12757",Code:"https://github.com/miulab/cuda-dst"}}]},s=function(){return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)("div",{className:"max-w-7xl mx-auto flex flex-row overflow-hidden min-h-60screen",children:(0,t.jsx)("div",{className:"basis-5/5 md:basis-5/5",children:(0,t.jsxs)("div",{className:"px-5 md:px-20 pt-5",children:[(0,t.jsx)("h1",{className:"text-5xl md:text-5xl font-bold py-10 text-center md:text-left",children:"Research."}),i.interest.map((e,a)=>(0,t.jsx)("div",{className:"text-base text-gray-500 dark:text-gray-300 pb-5 indent-8",children:e},a)),(0,t.jsx)("div",{className:"h-12"}),i.researchList.map((e,a)=>(0,t.jsxs)("div",{children:[(0,t.jsxs)("div",{className:"flex flex-col md:flex-row py-5 px-0 lg:px-5 justify-center items-center content-center",children:[(0,t.jsx)("div",{className:"lg:mr-5 max-md:max-w-96 max-md:mx-5 md:basis-2/6 lg:basis-1/4 md:min-h-48 mx-auto rounded-2xl overflow-hidden border flex justify-center items-center content-center bg-white h-fit max-md:mb-5",children:(0,t.jsx)("img",{src:e.image,className:"object-cover",alt:""})}),(0,t.jsxs)("div",{className:"basis-full md:basis-4/6 lg:basis-3/4 pl-5 max-md:pr-5",children:[(0,t.jsx)("div",{className:"pb-2",children:(0,t.jsx)("a",{className:"text-lg font-bold ",href:e.link,children:e.title})}),e.authors.map((a,n)=>(0,t.jsxs)("div",{className:"inline",children:[void 0!==a.link?(0,t.jsx)("a",{href:a.link,className:"text-base hover:underline text-blue-500 dark:text-blue-300"+(a.me?" font-bold":" font-light"),children:a.name}):(0,t.jsx)("span",{className:"text-base text-gray-500 dark:text-gray-300 font-light",children:a.name}),n!==e.authors.length-1?(0,t.jsx)("span",{className:"text-base text-gray-500 dark:text-gray-300",children:", "}):(0,t.jsx)(t.Fragment,{})]},n)),(0,t.jsxs)("div",{className:"text-base text-black dark:text-gray-300 font-normal",children:[e.journal,", ",e.year]}),(0,t.jsx)("div",{className:"text-base text-gray-500 dark:text-gray-300 py-2 font-light max-sm:hidden ",children:e.description},""),Object.entries(e.others).map((e,a)=>{let[n,i]=e;return(0,t.jsxs)("div",{className:"inline pr-1",children:["[ ",(0,t.jsx)("a",{href:i,className:"hover:underline text-blue-500 dark:text-blue-300",children:n})," ]"]},a)})]})]},e.title),a!==i.researchList.length-1?(0,t.jsx)("div",{className:"mx-3 md:mx-0 lg:mx-3 border-gray-400 border box-border mt-5 mb-12 md:my-2"},a):(0,t.jsx)(t.Fragment,{})]},a))]})})},""),(0,t.jsx)("div",{className:"h-48"})]})}}},function(e){e.O(0,[774,888,179],function(){return e(e.s=9004)}),_N_E=e.O()}]);